{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cnn import CNN\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'size' must be a 1-D Tensor of 2 elements: new_height, new_width",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e3acae5c20f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     ]\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0musing_cv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0m_train_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tamotoyoshifumi/GIT/is-this-obama/domain/cnn.pyc\u001b[0m in \u001b[0;36mread_image\u001b[1;34m(self, data_list, image_size)\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[0mjpeg_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjpeg_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                 \u001b[0mresized_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m                 \u001b[0mreshaped_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tamotoyoshifumi/.pyenv/versions/anaconda2-4.1.1/lib/python2.7/site-packages/tensorflow/python/ops/image_ops_impl.pyc\u001b[0m in \u001b[0;36mresize_images\u001b[1;34m(images, size, method, align_corners)\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\'size\\' must be a 1-D int32 Tensor'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     raise ValueError('\\'size\\' must be a 1-D Tensor of 2 elements: '\n\u001b[0m\u001b[0;32m    636\u001b[0m                      'new_height, new_width')\n\u001b[0;32m    637\u001b[0m   \u001b[0msize_const_as_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value_as_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'size' must be a 1-D Tensor of 2 elements: new_height, new_width"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #sing_cv = True\n",
    "    using_cv = False\n",
    "    \n",
    "    data_list = [\n",
    "        {\"folder\":\"img_face\",\"label\":\"0\"},\n",
    "        {\"folder\":\"img_face_non_obama\",\"label\":\"1\"}\n",
    "    ]\n",
    "    \n",
    "    # test data    \n",
    "    test_list = [\n",
    "        {\"folder\":\"img_face_test\", \"label\":\"0\"},\n",
    "        {\"folder\":\"img_face_test_non_obama\", \"label\":\"1\"}\n",
    "    ]\n",
    "    if not using_cv:\n",
    "        _train_image, train_label, _ = cnn.read_image(data_list)\n",
    "      \n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.initialize_all_variables())  \n",
    "        train_image = []\n",
    "        for img in _train_image:\n",
    "            print img\n",
    "            i = sess.run(img)\n",
    "            train_image.append(i)\n",
    "            \n",
    "        _test_image , test_label , test_image_list= read_image(test_list)  \n",
    "        test_image = []\n",
    "        for img in _test_image:\n",
    "            i = sess.run(img)\n",
    "            test_image.append(i)\n",
    "    else:\n",
    "        _train_image, train_label, _ = read_image_cv(data_list)\n",
    "        train_image = _train_image\n",
    "        _test_image , test_label , test_image_list = read_image_cv(test_list)  \n",
    "        test_image = _test_image\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        images_placeholder = tf.placeholder(\"float\", shape=(None, IMAGE_PIXELS))\n",
    "        labels_placeholder = tf.placeholder(\"float\", shape=(None, NUM_CLASSES))\n",
    "        # dropout率\n",
    "        keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "    \n",
    "        softmax = inference(images_placeholder, keep_prob)\n",
    "        loss_value = loss(softmax, labels_placeholder)\n",
    "        train_op = training(loss_value, LEARNING_RATE)\n",
    "        acc = accuracy(softmax, labels_placeholder)\n",
    "\n",
    "        # 保存の準備\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        # TensorBoardで表示する値の設定\n",
    "        summary_op = tf.merge_all_summaries()\n",
    "        summary_writer = tf.train.SummaryWriter(LOG_DIR, sess.graph)\n",
    "        \n",
    "        # 訓練の実行\n",
    "        for step in range(MAX_STEPS):\n",
    "            for i in range(len(train_image)/BATCH_SIZE):\n",
    "                # batch_size分の画像に対して訓練の実行\n",
    "                batch = BATCH_SIZE*i\n",
    "                sess.run(train_op, feed_dict={\n",
    "                  images_placeholder: train_image[batch:batch+BATCH_SIZE],\n",
    "                  labels_placeholder: train_label[batch:batch+BATCH_SIZE],\n",
    "                  keep_prob: 0.5})\n",
    "\n",
    "            # 1 step終わるたびに精度を計算する\n",
    "            #train_accuracy = sess.run(acc, feed_dict={\n",
    "            #    images_placeholder: train_image,\n",
    "            #    labels_placeholder: train_label,\n",
    "            #    keep_prob: 1.0})\n",
    "            #print \"step %d, training accuracy %g\"%(step, train_accuracy)\n",
    "               \n",
    "            train_loss = sess.run(loss_value,  feed_dict={\n",
    "                images_placeholder: train_image,\n",
    "                labels_placeholder: train_label,\n",
    "                keep_prob: 1.0})\n",
    "            print \"step %d, xentropy %s\"%(step, str(train_loss))\n",
    "            \n",
    "            if step % 10 == 0 and step > 0 and train_loss < 5.0:\n",
    "                display_test_prob(sess, softmax, test_image, \"オバマ\")\n",
    "\n",
    "            # 1 step終わるたびにTensorBoardに表示する値を追加する\n",
    "            summary_str = sess.run(summary_op, feed_dict={\n",
    "                images_placeholder: train_image,\n",
    "                labels_placeholder: train_label,\n",
    "                keep_prob: 1.0})\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "    # 訓練が終了したらテストデータに対する精度を表示\n",
    "    print \"test accuracy %g\"%sess.run(acc, feed_dict={\n",
    "        images_placeholder: test_image,\n",
    "        labels_placeholder: test_label,\n",
    "       keep_prob: 1.0})\n",
    "    \n",
    "\n",
    "    # 最終的なモデルを保存\n",
    "    save_path = saver.save(sess, \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
