{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cnn import CNN\n",
    "import tensorflow as tf\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "data_list = [\n",
    "    {\"folder\":\"img_face\",\"label\":\"0\"},\n",
    "    {\"folder\":\"img_face_non_obama\",\"label\":\"1\"}\n",
    "]\n",
    "    \n",
    "    \n",
    "test_list = [\n",
    "    {\"folder\":\"img_face_test\", \"label\":\"0\"},\n",
    "    {\"folder\":\"img_face_test_non_obama\", \"label\":\"1\"}\n",
    "]\n",
    "\n",
    "train_image, train_label, _ = cnn.read_image_cv(data_list)\n",
    "test_image , test_label , test_image_list = cnn.read_image_cv(test_list)  \n",
    "\n",
    "\n",
    "print(len(train_image))\n",
    "print(len(test_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, xentropy 2624.0\n",
      "step 1, xentropy 1484.24\n",
      "step 2, xentropy 190.571\n",
      "step 3, xentropy 165.152\n",
      "step 4, xentropy 98.7756\n",
      "step 5, xentropy 133.121\n",
      "step 6, xentropy 111.83\n",
      "step 7, xentropy 74.2802\n",
      "step 8, xentropy 76.3706\n",
      "step 9, xentropy 53.936\n",
      "step 10, xentropy 57.5725\n",
      "step 11, xentropy 45.3017\n",
      "step 12, xentropy 45.2449\n",
      "step 13, xentropy 32.2387\n",
      "step 14, xentropy 40.7304\n",
      "step 15, xentropy 28.8294\n",
      "step 16, xentropy 25.959\n",
      "step 17, xentropy 27.3314\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7a2ac931b5db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mimages_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mlabels_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             keep_prob: 0.5})\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#train_accuracy = sess.run(acc, feed_dict={\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tamotoyoshifumi/anaconda2/envs/py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tamotoyoshifumi/anaconda2/envs/py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tamotoyoshifumi/anaconda2/envs/py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/tamotoyoshifumi/anaconda2/envs/py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tamotoyoshifumi/anaconda2/envs/py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "        \n",
    "    images_placeholder = tf.placeholder(\"float\", shape=(None, cnn.IMAGE_PIXELS))\n",
    "    labels_placeholder = tf.placeholder(\"float\", shape=(None, cnn.NUM_CLASSES))\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "    \n",
    "    softmax = cnn.inference(images_placeholder, keep_prob)\n",
    "    loss_value = cnn.loss(softmax, labels_placeholder)\n",
    "    train_op = cnn.training(loss_value, cnn.LEARNING_RATE)\n",
    "    acc = cnn.accuracy(softmax, labels_placeholder)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "    #summary_op = tf.summary.merge_all()\n",
    "    #summary_writer = tf.summary.FileWriter (cnn.LOG_DIR, sess.graph)\n",
    "        \n",
    "        \n",
    "    for step in range(cnn.MAX_STEPS):\n",
    "        for i in range(len(train_image)/cnn.BATCH_SIZE):\n",
    "            batch = cnn.BATCH_SIZE*i\n",
    "            sess.run(train_op, feed_dict={\n",
    "                images_placeholder: train_image[batch:batch+cnn.BATCH_SIZE],\n",
    "                labels_placeholder: train_label[batch:batch+cnn.BATCH_SIZE],\n",
    "            keep_prob: 0.5})\n",
    "\n",
    "            #train_accuracy = sess.run(acc, feed_dict={\n",
    "            #    images_placeholder: train_image,\n",
    "            #    labels_placeholder: train_label,\n",
    "            #    keep_prob: 1.0})\n",
    "            #print \"step %d, training accuracy %g\"%(step, train_accuracy)\n",
    "               \n",
    "        train_loss = sess.run(loss_value,  feed_dict={\n",
    "            images_placeholder: train_image,\n",
    "            labels_placeholder: train_label,\n",
    "            keep_prob: 1.0})\n",
    "        print \"step %d, xentropy %s\"%(step, str(train_loss))\n",
    "            \n",
    "        if step % 10 == 0 and step > 0 and train_loss < 5.0:\n",
    "            cnn.display_test_prob(sess, softmax, test_image, \"obama\", images_placeholder,keep_prob)\n",
    "\n",
    "            #summary_str = sess.run(summary_op, feed_dict={\n",
    "            #    images_placeholder: train_image,\n",
    "            #    labels_placeholder: train_label,\n",
    "            #    keep_prob: 1.0})\n",
    "            #summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "  \n",
    "    print \"test accuracy %g\"%sess.run(acc, feed_dict={\n",
    "        images_placeholder: test_image,\n",
    "        labels_placeholder: test_label,\n",
    "       keep_prob: 1.0})\n",
    "    \n",
    "\n",
    "    save_path = saver.save(sess, \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2.7]",
   "language": "python",
   "name": "conda-env-py2.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
